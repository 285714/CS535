%
% To use this as a template for turning in your solutions, change the flag
% \inclsolns from 0 to 1. Make sure you include macros.tex in the directory
% containing this file. Edit the "author" and "collaborators" fields as
% appropriate. Write your solutions where indicated.
%

\documentclass[11pt]{article}

\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{comment}
\usepackage{amsmath,amssymb,amsthm}
\usepackage[hidelinks]{hyperref}
\usepackage[capitalise]{cleveref}

\include{macros}

%If you want to add more macros, do it like this
\newcommand{\dolphin}{\mathsf{DOLPHIN!!}}


\author{Ngu Dang and Fabian SpÃ¤h}
\title{The Hardness of Locating $\mathprob{MCSP}$ between $\P$ and $\NP$ \\ \smallskip \normalsize{(final draft)}}
\date{December 11, 2020}

\begin{document}
	\maketitle
	
\section{Introduction}

In the Minimum Circuit Size Problem (MCSP), we are given a truth table of some Boolean function together with a positive integer $s_n$ as input, and our task is to answer the question whether there exists a circuit of size at most $s_n$ that computes the function represented by the given truth table.

{
	% we can use this structure if you like it:
	\renewcommand{\arraystretch}{1.5}
	\begin{center}
		\begin{tabular}{|p{2cm}p{11cm}|}
			\hline
			Problem:
			&
			$\mathprob{MSCP}$
			\\
			\hline
			Input:
			&
			A tuple $\langle T_n, s_n \rangle$ consisting of a truth table $T_n$ for
			a Boolean function of arity $n$ and an integer $s_n$
			\\
			Question: & Is there a circuit $C_n$ of size at most $s_n$ computing $T_n$?
			\\
			\hline
		\end{tabular}
	\end{center}
}

Finding solutions to $\mathprob{MSCP}$ is an important part in the design
of integrated circuits where it is important to minimize space and execution
speed of a computational component.
However, motivations to study this problem are manifold.
%
One lies in meta-complexity, which is loosely the study of problems whose
instances contain some form of execution instruction themselves.
For each individual instance, we want to know how complex the object resulting
from this instruction is.
So, studying such a meta-problem entails determining the complexity of
determining complexity itself.
Now, $\mathprob{MCSP}$ is posed exactly as such a meta-problem, whereas the
instruction is stated in terms of a truthtable, and the complexity is
formalized as the size of a minimal circuit.
Given the expressiveness of truthtables and the importance of circuits in
representing computation, $\mathprob{MCSP}$ is therefore central to
meta-complexity.
%
As such, the minimization of circuits was already studied in the Soviet Union
as part of the question of whether brute-force search can be eliminated
in general \cite{trakhtenbrot84}.
%
We can also derive $\mathprob{MCSP}$ from the more general Kolmogorov complexity:
For a universal Turing machine $U$ and $x \in \zo^*$, define
$K_U(x) \coloneqq \min \set{ |d| \mid U(d) = x }$
as the minimum size of a program which generates $x$.
Now, the decision version of $K_U$ is undecidable, so weaker notions
restricting at least the execution time of $U$ are studied, and
$\mathprob{MCSP}$ is one of them.
%
This also relates the study of $\mathprob{MCSP}$ to the typical questions in
information theory. In particular, the minimum circuit size puts a number on
the information stored in a truth table $T_n$.
%
Moreover, the promise version of $\mathprob{MCSP}$ is essential to computational
learning theory:
If we would want to know what hidden Boolean function produced a certain set of
$n$-dimensional training samples, we can---in accordance with Occam's
razor---ask for the minimum circuit which coincides with all training samples.
The widely applied decision tree algorithms are just a special case of this,
but circuits are, of course, more succinct.
%
Finally, and we will see this in this paper,
$\mathprob{MCSP}$ has strong connections to the existence of
pseudorandom generators, an important assertion in cryptography.

It is easy to see that $\mathprob{MCSP}$ is in $\NP$. Namely, we can define a certificate as some proposed circuit $C$ of size at most $s_n$, and verify whether $C$ computes each entry of the truth table correctly in polynomial time.
% With that being said, a natural question arises: Is $\mathprob{MCSP}$  $\NP$-complete?
%
Despite the huge interest and long history of research in $\mathprob{MSCP}$,
we know relatively little beyond that.
%
In ``Circuit Minimization Problem,'' Valentine Kabanets and Jin-Yi Cai addressed the difficulty of showing $\mathprob{MCSP}$ to be $\NP$-hard \cite{10.1145/335305.335314}. They do this by providing some strong implications if there exists a polynomial-time reduction $R$ from $\mathprob{SAT}$ to $\mathprob{MCSP}$ that is ``natural,'' in the sense that the size of the output depends on the size of the inputs only, and these sizes are polynomially related. Furthermore, the authors pointed
out that there has also been no proof that $\mathprob{MCSP} \notin \P$. Clearly, such proof would imply $\P \neq \NP$, which goes beyond the currently known techniques. The authors did, however, provide some clues on why this conjecture seems plausible; again, by offering consequences of questionable likelihood if $\mathprob{MCSP} \in \P$.

In this review, we will first give some definitions required to understand the main results and key theorems of the paper in Section~2. Section~3 introduces some main consequences of $\mathprob{MCSP}$ being $\NP$-hard under ``natural'' reductions and of $\mathprob{MCSP} \in \P$. Finally, we conclude the review by giving remarks and directions for further research on this topic in Section 4.


% META-complexity (how hard is it to proof a problem is hard?)
%
% Conclusion:
% - No NP-hardness result known for $\mathprob{MCSP}^A$ for any oracle $A$;
% - some success in proving $\NP$-hardness for some restricted cirucit designs

% Showing $\NP$-completeness of $\mathprob{MCSP}$ is at least as hard as showing
% all of its ramnifications (and showing that there's a non-natural reduction):
% ``If one were to show ... then one will have to show ...''
% ---
% What do we believe about these ramnifications (give intuition why they might
% be wrong)


% NATURAL PROOFS: While these proofs are in some sense "natural", it can be shown (assuming a widely believed conjecture on the existence of pseudorandom functions) that no such proof can possibly be used to solve the P vs. NP problem.


\section{Preliminaries}

We begin by introducing some useful background, including the definition
of some complexity classes, the concept of natural reductions,
and pseudorandomness.

\subsection{Complexity Classes}
Here, we provide the necessary definitions for complexity classes used
throughout this paper.
For more details and a full discussion, see \cite{arora2009}.

\begin{definition}
  The class \emph{sub-exponential} is
  $\class{SUBEXP} \coloneqq \bigcap_{\epsilon > 0} \TIME(2^{n^{\epsilon}})$.
\end{definition}

Note that $\class{SUBEXP}$ is not empty, even though it is defined as an infimum
over complexity classes. This is because a language might be decided by a
different TM for every $\varepsilon > 0$.

\begin{definition}
	The class $\class{QP}$ of languages decided by a TM in
	\emph{quasi-polynomial} time defined by
	\[
	\class{QP}
	\coloneqq
	\TIME(n^{\mathrm{polylog}(n)})
	=
	\bigcup_{c > 1}\TIME(2^{\log^c n})
	=
	\bigcup_{c > 1}\TIME(n^{\log^c n})
	\]
\end{definition}
We obtain the last equality since
$2^{(\log n)^{c+1}} = (2^{\log n})^{\log^c n} = n^{\log^c n}$.
%
Note that $\class{QP}$ contains $\P$ since
$\mathrm{polylog}(n) \in \Omega(1)$.

Also, $\class{SUBEXP}$ contains $\class{QP}$ since for every
$\varepsilon > 0$ and $c > 1$ holds that
$\exp(\log^c n) \in o(\exp(n^\varepsilon))$.\footnote{To analyze the
relationship of exponentials, the following proofs useful:
For functions $f, g \colon \N_+ \to \N_+$ holds
$2^{f(n)} \in o(2^{g(n)})$ if and only if $g(n) - f(n) \to \infty$ for
$n \to \infty$.
This is easily seen by using the limit definition of Landau symbols as
\[
  f(n) \in o(g(n))
  \iff
  0 = \lim_{n \to \infty} \frac{2^{f(n)}}{2^{g(n)}}
  = \lim_{n \to \infty} \exp(f(n) - g(n))
  \iff
  \lim_{n \to \infty} f(n) - g(n) = -\infty \,.
\]
}


\begin{definition}
  The class \emph{exponential time with linear exponent} is defined as
	$\class{E} \coloneqq \TIME(2^{O(n)})$.
\end{definition}
Since $\log^c n \in O(n)$ for any $c > 0$, we obtain that
$\class{QP} \subseteq \class E$.
%
Finally, we introduce \emph{infinitely-often simulations} trough a modifier to
a complexity class $C$.
\begin{definition}
  A language $L$ belongs to the class
  $\io C$ if there is a language $A \in C$ such that
  $A$ and $L$ agree on infinitely many input lengths, i.e.
  \[
    |\set{ n \in \N \mid \forall x \in \{0,1\}^n\ A(x) = L(x) }| = \infty
  \]
\end{definition}
Note that $C$ is obviously containend in $\io C$.
For brevity, we usually write $C \subseteq C$ (i.o.) or $C = C$ (i.o.)
in place of $C' \subseteq \io C$ and $C' = \io C$, respectively.



\subsection{Natural Reductions}

Let us now introduce the notion of a \textit{natural reduction}.
Intuitively, a polynomial-time reduction is natural if its output size
depends only on the size of the input. Formally, we define it as follows.
% In this subsection, we will provide you the definition of \textit{Natural Reduction}. Intuitively speaking, for two problems $A$ and $B$, and a Karp reduction from $A$ to $B$, we say the reduction $R$ is natural if, for any instance $I$ of $A$, the length of the output depends only on the input length, and those lengths are polynomial related. To make sure that the readers can get a better understanding of the proofs that we introduce in the later sections, we provide the formal version which specifies more technical properties of the ``mapping'' process. 
% should we? ans: fixed :)) what do you think? :))

\begin{definition}
  Assume we are given two languages $A$ and $B$, where $B$ describes the
  decision version of a search problem, meaning its instances are of the kind
  $\langle y, s \rangle \in B$ where $s \in \N$ is a numerical parameter.
  A many-one reduction $R = \langle R_1, R_2 \rangle$ from $A$ to $B$, whereas
  $R_1$ maps to instances $y$ of the original search problem and $R_2$ to the
  parameters $s$, is called \emph{natural} if for all instances $x$ of $A$ holds
  that
  \begin{itemize}
    \item there exists a $c \in \R_+$ such that
      $|x|^{1/c} \le |R_1(x)| \le |x|^c$, meaning $R_1$ does not suddenly grow or
      shrink, and
    \item $R_2$ depends only on the length of the instance $x$, i.e. there
      exists a function $f \colon \N \to \N$ such that $R_2(x) = f(|x|)$.
  \end{itemize}
\end{definition}
	
% \begin{example}
%   $\mathprob{SAT} \leq_p \mathprob{3SAT}$ is ``natural,'' given by $R = R_1(\varphi) = \varphi'$ where $\varphi$ is some regular $\mathprob{CNF}$ and $\varphi'$ is a $\mathprob{3CNF}$-formula. The general strategy for the reduction is to split some clause $C$ in $\varphi$ of size $k > 3$ into a pair of two equivalent clauses $C_1$ of size $k - 1$ and $C_2$ of size $3$ and we repeat the process until we get the desired $\mathprob{3CNF}$ formula, $\varphi'$. Thus, it is easy to see that the length of $\varphi'$ is not stretched by much as we just add more clauses solely based on everything from the original formula $\varphi$. In this example, $R_2$ is not needed as the $\mathprob{3SAT}$ problem does not require any numerical value.
% \end{example}

% \begin{example}
%   $\mathprob{3SAT} \leq_p \mathprob{INDSET}$\footnote{$\mathprob{INDSET} = \{ \langle G, k \rangle \mid G \text{ has independent set of size k}\}$} is ``natural,'' given by $R = \langle R_1(\varphi) = G, R_2(\varphi) = k$ where $\varphi$ is some $\mathprob{3CNF}$ formula, $G$ is a graph, and $k$ is the target size of the independent set that we want for $G$. The general strategy for the reduction is to create a graph of $7m$ vertices from a $\mathprob{3CNF}$ formula of $m$ clauses, and the number $k$ can be easily determined using $m$, the number of clauses. It is easy to see that the length of the output of the reduction is not stretched by much. \footnote{for full details of the reductions of both examples, see \cite{arora2009}, chapter 2, page 49 and 51 respectively.}
% \end{example}
	
All $\NP$-complete problems we are aware of seem to be complete under natural reductions. This is not special for a polynomial-time reduction to an
unparameterized problem, as we can usually pad the reduct to conform to
the specific length. However, so far we are not aware of any parameterized
problem which is $\NP$-complete under general many-one reductions but not
under a natural reduction.
To give a good understanding, we wrap up with the following example of an
unnatural reduction made natural.

\begin{example}
  We reduce from
  $\mathprob{Partition}$\footnote{The partition problem asks, given a multiset
  of positive integers $\{a_1, \dots, a_n\}$, whether there exists a partition
  $(S,T)$ of $\{1, \dots, n\}$ such that
  $\sum_{i \in S} a_i = \sum_{i \in T} a_i$.}
  to
  $\mathprob{SubsetSum}:$\footnote{Subset sum asks for an instance
  $\langle A, s \rangle$ of a multiset of positive integers
  $A = \{a_1, \dots, a_n\}$ and an integer $s$, whether there exists a subset
  $S \subseteq \{1, \dots, n\}$ such that
  $s = \sum_{i \in S} a_i$.}
  \[
    R(\{a_1, \dots, a_n\}) \coloneqq
    \left\{
      \begin{array}{ll}
        \langle \{2, 4, 8\}, 7 \rangle
          & \textrm{if } \sum_{i=1}^n a_i \equiv_2 1 \\
        \langle \{a_1, \dots, a_n\}, \frac 1 2 \sum_{i=1}^n a_i \rangle
          & \textrm{otherwise} \,. \\
      \end{array}
    \right.
  \]
  Now, while this reduction is correct (if $\sum_{i=1}^n a_i$ is congruent to 1
  modulo 2, it is impossible to divide the set into two partitions of equal sum;
  the tuple $\langle \{2, 4, 8\}, 7 \rangle$ is a no-instance to
  $\mathprob{SubsetSum}$) and can be carried out in polynomial time.
  It is not natural for two reasons:
  First, the output size does not strictly depend on the input size as, in the
  case of an obvious no-instance to $\mathprob{Partition}$, we map directly to a
  no-instance of $\mathprob{SubsetSum}$ of constant size.
  Second, the numerical parameter $s$ is not a function of the input
  size only. For example, the two instances $\{1, \dots, 1\}$ ($n$-times) and
  $\{2^n\}$ are of equal size, but have totally different sums.
  With a little more care, we can, however, make this a natural reduction: Let
  \[
    \begin{array}{rrl}
      R'(\{a_1, \dots, a_n\}) \coloneqq
        \langle \{2 a_1, \dots, 2 a_n, r,
         2^{\sigma+2} \rangle
      &\textrm{where}&
      \sigma \coloneqq \mathrm{size}(\{a_1, \dots, a_n\}) \\
      &\textrm{and}&
      r \coloneqq 2^{\sigma+2} - \sum_{i=1}^n a_i \,.
    \end{array}
  \]
  Now, the numerical parameter $s$ is obviously only a function in the input
  size $\sigma$. Regarding correctness, first note that
  $2^{\sigma+2} > \sum_{i=1}^n 2 a_i$. This implies that any subset with a sum
  of $2^{\sigma+2}$ necessarily contains $r$ and thus
  $
    \textstyle
    2^{\sigma+2} = r + \sum_{i \in S} 2a_i
    \iff
    \frac 1 2 \sum_{i=1}^n a_i = \sum_{i \in S} a_i
  $
  where $S$ is the original subset without $r$.
\end{example}


% $L \in \almosteverywhere C$


% \subsection{Pseudorandom generator}
% \label{subsect:pseudorandom}
% \begin{definition}
%   \textit{Pseudorandom generators}: A distribution $R$ over $\{0, 1\}^m$ is ($S, \epsilon$)-pseudorandom (for $S \in \N$, $\epsilon > 0$) if for every circuit $C$ of size at most $S$.
%   \[|Pr[C(R) = 1] - Pr[C(U_m) = 1]| < \epsilon\]
%   where $U_m$ denotes the uniform distribution over $\{0, 1\}^m$.
%   
%   Let $S: \N \rightarrow \N$ be some function. A $2^n$-time computable function $G: \{0, 1\}^* \rightarrow \{0, 1\}^*$ is an $S(l)$-\textit{pseudorandom generator} if $|G(z)| = S(|z|)$ for every $z \in \{0, 1\}^*$ and for every $l \in \N$ the distribution $G(U_l)$ is $(S(l)^3, 1/10)$-pseudorandom.
%   
%   For more details and a full discussion of this topic, prefer to chapter 20 of \cite{arora2009}
% \end{definition}
%
% \begin{definition} (\cite{10.1145/335305.335314})
%   The \textit{hardness} $H(G_k)$ of a pseudorandom generator $G_k: \{0, 1\}^k \rightarrow \{0, 1\}^{2k}$ is defined as the minimal $s$ such that there exists a circuit $C$ of size at most $s$ for which
%   \[|Pr_{x \in \{0, 1\}^k}[C(G_k(x)) = 1] - Pr_{x \in \{0, 1\}^{2k}}[C(y) = 1]| \geq 1/s\]
%   
%   The pseudorandom generator $G_k$ is called \textit{strong} if it has hardness $H(G_k) > 2^{k^{\Omega(1)}}$ 
% \end{definition}


\subsection{Pseudorandomness}

Given a short string of truly random bits, a \emph{pseudorandom
generator} tries to enlarge this sequence to obtain more
``artificial'' randomness.
We can evaluate the randomness of this resulting sequence is in the
fashion of meta-complexity by testing how likely the best adversary is in
distinguishing it from true randomness:

\begin{definition}[Pseudorandom Generators]
  A family $\{G_n\}_n$ with $G_n \colon \zo^n \to \zo^{S(n)}$ is called an
  $S(n)$-pseudorandom generator if $\{G_n\}_n \in \class E$ and
  \[
    \Pr_{x \in \zo^n}[C(G(x)) = 1] -
    \Pr_{y \in \zo^{S(n)}}[C(y) = 1] < \frac 1 {10}
  \]
  for every circuit $C$ of size at most $S(n)^3$.
\end{definition}

% We also call $S(n)$ the stretch of $G$.
The existence of certain pseudorandom generators would allows us to
derandomize algorithms in $\BPP$. The basic idea is to replace the randomness
used in a probabilistic algorithm with pseudorandmoness generated from a
sufficiently small source of true randomness. We then try the algorithm on the
pseudorandomness generated from each choice in this small source while the
assumption guarantees that it cannot distinguish it from true randomness.
If $S(n)$ is large enough, this leads to an efficient derandomization.
% Now, enumerating the random strings of the
% latter leads to a deterministic algorithm which is correct due to the
% assumption that no algorithm can distinguish between true randomness and
% our generated pseudorandomness.

\begin{definition}[One-Way Functions]
  A polynomial-time computable
  function $f \colon \zo^* \to \zo^*$ with 
  $|f(x)| = |x|$
  is a \emph{one-way function}
  if for every constant $c$ and every non-uniform algorithm $A$ running in
  time $O(n^c)$ holds
  \[
    \Pr_{x \in \zo^n}\left[A(f(x)) \in f^{-1}(f(x))\right] \le \frac 1 {n^c}
  \]
  for every $n \in \N$.
\end{definition}

In words: no matter how hard an $O(n^c)$ time-constrained adversary tries to
find a pre-image of $f(x)$, he can only do so with probability at most
$1 / n^c$.
Note that this statement is made about the average-case hardness of inverting
$f$. As the adversary is time constrained, we can therefore construct one-way
functions from problems that we belive to be hard on average.
%
As such, one-way functioins are generally assumed to exist.
Moreover, we can show that the existence of certain pseudorandom generators
implies the existence of one-way functions \cite{hastad99}.
% One such problem is integer factoring, i.e. the inverse of multiplication.
%

In particular,
the existence of one-way functions is vital for cryptography. For example,
Bitcoin's blockchain consensus algorithm relies on the hardness of inverting
a hash-function which is believed to be one-way.
If an adversary would find a way to circumvent the brute-force search
efficiently and with good probability, he would be able to take control over
the protocol.
%

We wrap up with defining a special kind of pseudorandom generator:

\begin{definition}(\cite{10.1145/335305.335314})
	The \textit{hardness} $H(G)$ of a pseudorandom generator $G: \{0, 1\}^n \rightarrow \{0, 1\}^{2n}$ is defined as the minimal $s$ such that there exists a circuit $C$ of size at most $s$ for which
	\[\Pr_{x \in \{0, 1\}^n}[C(G_n(x)) = 1] - \Pr_{x \in \{0, 1\}^{2n}}[C(y) = 1] \geq 1/s\]
	
	The pseudorandom generator $G$ is called \textit{strong} if it has hardness $H(G) > 2^{n^{\Omega(1)}}$ 
\end{definition}


% ------------------------------------------------------------------------------


\section{Main Results}

\subsection{MCSP and NP-completeness}
\label{subsect:MCSP-NP}

To begin with, let us make it clear that we do now know whether
$\mathprob{MCSP}$ is $\NP$-hard.
Yet, the difficulty of this proof can be made explicit by looking at
some implications it has for circuit complexity and $\BPP$ which are both
beyond currently known techniques.
%
In other words, proving the $\NP$-hardness of $\mathprob{MCSP}$ can be shown
to be as challenging as finding proofs for other long-standing and
problems known to be difficult.

Now, let us look at the first key theorem regarding an
implication for circuit complexity if $\mathprob{MCSP}$ is $\NP$-hard
under a natural reduction.

\begin{theorem}[\cite{10.1145/335305.335314}]
  \label{thm:15-1}
  If $\mathprob{MCSP}$ is $\NP$-hard under a natural reduction from
  $\mathprob{SAT}$, then $\class{E}$ contains a family of Boolean functions
  $f_k$ not in $\io \Ppoly$, i.e. of superpolynomial circuit complexity.
\end{theorem}

Before we move on to the proof, let us examine some lemmata that are useful
for establishing this result.

\begin{lemma}
	\label{lem:qp-collapse}
	$\class{QP}^{\class{QP}} \subseteq \class{QP}$.
\end{lemma}

\begin{proof}
  Let $M$ be a TM dedicing a language $L \in \class{QP}^{\class{QP}}$ in
  quasi-polynomial time, say $\exp(\log^c n)$.
  We show that carrying out the oracle computation instead of calling the
  oracle does still guarantee a quasi-polynomial running time. To this end,
  let $M'$ be the TM deciding the $\class{QP}$-oracle, say in time
  $\exp(\log^{c'} m)$.
  Now, any input to $M'$ is at most of length $m = \exp(\log^c n)$. We
  therefore need time at most
  $\exp(\log^c (\exp(\log^c n))) = \exp(\log^{cc'} n)$
  for one oracle computation. At the same time, there are at most
  $\exp(\log^c n)$ calls, resulting in a total running time bound of
  $\exp(\log^c (\exp(\log^{cc'} n))) = \exp(\log^{c^2 c'} n)$
  which is still quasi-polynomial.
\end{proof}

\begin{lemma}
	\label{lem:ph-sub-qp}
	If $\NP \subseteq \class{QP}$ then
	$\class{PH} \subseteq \class{QP}$.
\end{lemma}

\begin{proof}
  Recall that we can define $\class{PH}$ in terms of oracles by
  \[
    \class{PH} =
    \bigcup_{n > 0} \underbrace{\NP^{\NP^{\cdots^{\NP}}}}_{n \textrm{ times}}
    \,.
  \]
  We can use a straithgforward induction over $n$ to show that
  $\class{PH} \subseteq \class{QP}$.
  Note that the induction basis is just the assumption.
  Furthermore, by the inductive hypothesis, we have that
  \[
    \underbrace{\NP^{\NP^{\cdots^{\NP}}}}_{n \textrm{ times}}
    \subseteq
    \class{QP}
    \quad
    \Longrightarrow
    \quad
    \underbrace{\NP^{\overbrace{
      \NP^{\NP^{\cdots^{\NP}}}
    }^{n \textrm{ times}}}}_{n+1 \textrm{ times}}
    \subseteq
    \NP^{\class{QP}} \,.
  \]
  Now, $\NP^{\class{QP}} \subseteq \class{QP}^\class{QP} \subseteq \class{QP} $
  by Lemma~\ref{lem:qp-collapse}.
\end{proof}

\begin{lemma}
	\label{lem:qp-super-circ}
	$\class{QP}^{\class{\Sigma}^p_k}$ contains a language which does not belong
	to $\io \Ppoly$ for some $k \in \N$.
\end{lemma}

\begin{proof}
	The proof follows a nonuniform diagonalization argument. We first define
	a language which will be hard to compute for any polynomial-size circuit
	family:
	Let $L'$ be the language consisting of tuples
	$\langle x, 1^{\exp(\log^3 n)} \rangle$
	with $n \coloneqq |x|$
	such that $C(x) = 1$ where $C$ is the
	lexicographically first circuit of size $\exp(\log^3 n)$ which is not
	computed by any circuit of size $\exp(\log^2 n)$.
	The existence of such a circuit for sufficiently large $n$ follows from a
	slightly more careful analysis of the nonuniform hierarchy theorem
	(Theorem~6.22).
	
	We can decide membership $\langle x, 1^{\exp(\log^3 n)} \rangle \in L'$
	by a $\class{\Sigma}^p_4$-oracle as in Problem~(1c) of Homework~7.
	Finally, we define our language $L$ of superpolynomial circuit complexity
	as the output of a $\class{QP}^{\class{\Sigma}^p_4}$-machine: Given an input
	$x \in \{0,1\}^n$, query the oracle for $L'$ with
	$\langle x, 1^{\exp(\log^3 n)} \rangle$ and output its answer.
	
	We constructed this language such that it is hard for a polynomial-size
	circuit to compute. To see this, assume to the contrary that there is
	a $n^a$-size circuit family.
	However, since $n^a \in o(\exp(\log^2 n))$ and we particularly excluded any
	circuits of size less than $\exp(\log^2 n)$, this is a contradiction.
\end{proof}

\begin{lemma}
  \label{lem:num-of-circs}
  There are $O(s^{3s})$ different circuits of size $s$.
  In particular, there are
  \begin{enumerate}
    \item $n^{\mathrm{polylog}(n)}$ circuits of size $\log^c n$ for any
      $c > 0$ and

    \item $O(2^{n^{2 \varepsilon}})$ circuits of size
      $n^\varepsilon$ for any $\varepsilon > 0$.
  \end{enumerate}
\end{lemma}

\begin{proof}
  In a circuit with $s \in \N$ many gates and inputs, each gate is connected to
  at most two out of $s$ gates, and computes one of the functions
  $\land, \lor, \neg$.
  This means, there are at most $3 \cdot s^2$ choices to construct each gate
  and thus $(3 s^2)^s = O(s^{3s})$ choices to construct the whole circuit.

  \begin{enumerate}
    \item Setting $s \coloneqq \log^c n$ gives us
      \[
        O((\log^c n)^{3 \log^c n})
        =
        O(2^{(\log^{3c} n) \cdot (\log^c n)})
        =
        O(2^{\log^{4c} n})
        =
        n^{\mathrm{polylog}(n)}
      \]
      many ways to construct a circuit of size $\log^c n$, while

    \item setting $s \coloneqq n^\varepsilon = 2^{\varepsilon \log n}$ yields
      $
        O((2^{\varepsilon \log n})^{n^\varepsilon})
        =
        O(2^{n^{2 \varepsilon}})
      $
      different circuits of size $n^\varepsilon$.
  \end{enumerate}
\end{proof}

We now know have enough tools to prove Theorem~\ref{thm:15-1}.
We remind ourselves of the statement to prove:
If there is a natural polynomial-time reduction from
$\SAT$ to $\mathprob{MCSP}$, then $\class E$
contains a family of Boolean functions $f_k$ of superpolynomial circuit
size.

\begin{proof}[Proof (Theorem~\ref{thm:15-1})]
  We separate the prove along two cases.
	\begin{itemize}
		\item Case 1: $\NP \subseteq \class{QP}$

      Applying Lemma~\ref{lem:qp-collapse} and Lemma~\ref{lem:ph-sub-qp} to
      this assumption yields
      $\class{QP}^{\class{PH}} \subseteq \class{QP}^{\class{QP}} \subseteq
       \class{QP} \subseteq \class{E}$.
      Lemma~\ref{lem:qp-super-circ} shows that $\class E$ also contains
      a language of superpolynomial circuit complexity (i.o.).
      % how does
      %   'a language of superpolynomial circuit complexity'
      % relate to
      %   'a family of Boolean functions not in P/poly'
      % ?
      Hence, $\class{E} \not\subseteq \io\Ppoly$\\
		
		\item Case 2: $\NP \not\subseteq \class{QP}$

      While it is (computationally) trivial to choose a no-instance for $\SAT$
      of any given size, it is not clear how to do so for $\mathprob{MCSP}$.
      The key idea for this part is, therefore, to use the natural reduction $R$
      to obtain hard instances for $\mathprob{MCSP}$, i.e. a family of
      truthtables which cannot be represented by ciruits of polynomial size.

      We start out by picking a quite arbitrary infinite set $U$ of 
      unsatisfiable CNF-formulae, say,
      $U \coloneqq \set{ \phi_n \mid n \in \N }$
      where
      \[
        \phi_n(x_1, \dots, x_n) \coloneqq
        (x_1 \land \bar x_1) \land
        (x_3 \land x_4 \land \cdots \cdots \cdots \land x_n) \,.
      \]
      By construction, $|\phi_n| \in \Theta(n)$.
      Now, based on this, we want to apply $R$ to define our hard language.
      %
      For each $k \in \N$, let $T_k$ be the truthtable in $k$-variables such
      that $\langle T_k, s_n \rangle = R(\phi_n)$ and $n$ is minimal.
      If no $\phi_n$ maps to a truthtable in $k$ variables, simply let
      $T_k \equiv 0$.

      We know that $R$ is natural, which in particular implies
      $n^{1/c} \le |T_k| \le n^c$ (with an appropriate $c \in \N$)
      for every $\phi_n$ mapping to a truthtable $T_k$.
      Since $|T_k| = 2^k$, this is equivalent to
      $\log (n^{1/c}) \le k \le \log (n^c)$
      implying $k = \Theta(\log n)$ or $n = 2^{\Theta(k)}$.
      %
      Now, we proceed with defining our hard language
      \[
        L \coloneqq
        \set{
          x \in \{0,1\}^k \mid
          k \in \N,
          T_k(x) = 1
        }
      \]
      to obtain the following.
      \begin{enumerate}[(i)]
        \item $L \in \class E$:
          %
          We show how to construct a machine to decide $L$ in time
          $2^{O(k)}$.
          Given an input $x \in \{0,1\}^k$, we first need to know which
          $\phi_n$ maps to $T_k$ under $R$.

          To each candidate $\phi_n$ for $n \in \N$, we apply $R$ and obtain
          $\langle T_{k'}, s_n \rangle = R(\phi_n)$.
          We then compare whether $k = k'$ and if so, output $T_k(x)$.
          The reduction $R$ runs in polynomial time, say $n^a$ for an
          $a \in \N$.
          %
          By the above construction, $n = 2^{\Theta(k)}$ which means we
          only need to check $2^{\Theta(k)}$ candidates whereas each check
          runs in time at most $n^a = (2^{\Theta(k)})^a = 2^{\Theta(k)}$.
          %
          If no candidate maps to a truthtable on $k$ variables, we know
          that $T_k \equiv 0$ by definition and reject since
          $T_k(x) = 0 \not= 1$.
          %
          Overall, the decision procedure took time $2^{O(k)}$, proving
          that $L \in \class E$.

        \item $L \not\in \Ppoly$:
          We start by showing that the parameter $s_n$ produced by $R$ is
          superpolynomial in $\log n$.
          Let us thus assume to the contrary that it is bound by a polynomial
          $s_n \le \log^b n$ for any $b \in \N$.
          %
          Now, this yields a simple strategy to decide $\SAT$ in
          quasi-polynomial time:
          Given a CNF-formula $\phi$ of size $n$, we apply
          $R$ to obtain $\langle T_{k'}, s_n \rangle \coloneqq R(\phi)$
          with $s_n \le \log^b n$.
          We are going to decide the membership of this instance to
          $\mathprob{MSCP}$ instead of solving
          the original satisfiability problem.
          By Lemma~\ref{lem:num-of-circs}, there are at most
          $n^{\mathrm{polylog}(n)}$ circuits of size $s_n$.
          We enumerate these and check for each circuit whether
          it represents $T_{k'}$.
          Note that testing whether a circuit $C$ of size $s_n$ represents
          $T_{k'}$ only requires us to do $2^{k'}$ evaluations of $C$, each of
          which take time $O(s_n)$.
          Overall, we can decide the membership to $\mathprob{MCSP}$, and
          as such the satisfiability of $\phi$, in quasi-polynomial time.
          However, this implies that $\SAT \in \class{QP}$
          contradicting our assumption that $\NP \not\subseteq \class{QP}$.

          We therefore established that $s_n$ is superpolynomial in $\log n$.
          At the same time, $R$ is a natural reduction, meaning that $s_n$ is
          the same for every input of size $n$.
          In particular, we obtain that since we set
          $\langle T_k, s_n \rangle = R(\phi_n)$, the parameter
          $s_n$ is superpolynomial in $\log n = \Theta(k)$.
          As $\phi_n$ is a no-instance to $\SAT$, we conclude that
          $T_k$ cannot be represented by a polynomial-size circuit family.
          In other words, $L \not\in \Ppoly$.
          %
          Being more careful, we furthermore obtain that any polynomial-size
          circuit family can only agree with $T_k$ on finitely many
          input lengths. The reason for this is that
          $s_n \in \omega(\mathrm{poly}(k))$ guarantees
          by definition the existence of a $k_0 \in \N$ such that
          $\mathrm{poly}(k) < s_n$ for all $k > k_0$.
          We conclude that $L \not\in \io \Ppoly$.
      \end{enumerate}
	\end{itemize}
\end{proof}

With the same techniques but a different bound on the circuit size, we can
obtain a very similar statement. The only additional ingredient is
the exponential-time hypothesis which is, however, widely assumed to
be true \cite{impagliazzo99}.
The claim is that $\NP \not\subseteq \class{SUBEXP}$, or equivalently, that
$\SAT$ requires exponential time.

\begin{theorem}[\cite{10.1145/335305.335314}]
  \label{thm:15-2}
  If $\mathprob{MCSP}$ is $\NP$-hard under a natural reduction from
  $\mathprob{SAT}$ and $\NP \not\subseteq \class{SUBEXP}$, then
  $\class{E}$ contains a family of Boolean functions
  $f_k$ of circuit complexity $2^{\Omega(k)}$ (i.o.)
\end{theorem}

\begin{proof}
  This proof follows similarly to the previous statement.
  In fact, let the language $L$ and pairs $\langle T_k, s_n \rangle$ be defined
  as in the proof for Theorem~\ref{thm:15-1}.
  The difference is that here, we show that a more restrictive bound on
  $s_n$ contradicts the stronger assumption $\NP \subseteq \class{SUBEXP}$ as
  this bound would allow $\SAT$ to be solved in subexponential time.

  To this end, assume that $s_n \in O(n^\varepsilon)$ for any
  $\varepsilon > 0$.
  We pursue the same strategy to decide the satisfiability of a CNF formula
  $\phi$: Using the reduction $R$, map it to
  $\langle T_{k'}, s_n \rangle \coloneqq R(\phi)$.
  Lemma~\ref{lem:num-of-circs} shows that there are
  $O(2^{n^{2 \varepsilon}})$ circuits of size at most $s_n$.
  Enumerating all such circuits (1) and checking whether they represent
  $T_{k'}$ by evaluating (3) all assignments (2) therefore takes time
  \[
    \underbrace{O(2^{n^{2 \varepsilon}})}_{\textrm{(1)}} \cdot
    \underbrace{O(2^{k'})}_{\textrm{(2)}} \cdot 
    \underbrace{O(s_n)}_{\textrm{(3)}}
    =
    O(2^{n^{2 \varepsilon}}) \cdot
    \mathrm{poly}(n) \cdot
    O(n^\varepsilon)
    =
    O(2^{n^{3 \varepsilon}}) \,.
  \]
  So, if we assume to the contrary that
  $s_n \in O(n^\varepsilon)$ for every $\varepsilon > 0$,
  we also obtain that we can decide the satisfiability of $\phi$ in time
  $O(2^{n^{3 \varepsilon}})$ for every $\varepsilon$, i.e.
  in subexponential time.
  However, $\SAT \in \class{SUBEXP}$
  contradicts the assumption $\NP \subseteq \class{SUBEXP}$.

  We can conclude that instead, $s_n \in \Omega(n^\varepsilon)$
  for an $\varepsilon > 0$.
  With $n = 2^{\Theta(k)}$, this shows that
  $s_n \in \Omega(2^{\varepsilon \Theta(k)}) = 2^{\Omega(k)}$.
  %
  Now, with the same argument as above, we know that $L$ can only be decided
  by a $2^{\Omega(k)}$ size circuit family. We have already proven that
  $L \subseteq \mathbf E$, which concludes the proof.
\end{proof}

Now, we will look at the implications for $\BPP$ when $\NP$-hard under a natural reduction from $\mathprob{SAT}$. The following two theorems on hardness-randomness trade-offs are needed to establish the one about $\BPP$.

\begin{theorem}[\cite{babai1993bpp}]
  \label{thm:bpp-in-subexp}
	If the class $\EXP$ contains a family of Boolean functions of superpolynomial circuit complexity (i.o.), then $\BPP \subseteq \class{SUBEXP}$ (i.o.).
\end{theorem}

\begin{theorem}[\cite{impagliazzo1997}]
  \label{thm:bpp-eq-p}
	If the class $\class{E}$ contains a family of Boolean functions $f_n: \{0, 1\}^n \rightarrow \{0, 1\}$ of circuit complexity at least $2^{\epsilon n}$ for some $\epsilon > 0$, (i.o.), then $\BPP = \P$ (i.o.).
\end{theorem}

\begin{theorem}[\cite{10.1145/335305.335314}]
	\label{thm:BPPimplication}
	If $\mathprob{MCSP}$ is $\NP$-hard under a natural reduction from $\mathprob{SAT}$, then
	\begin{enumerate} [1.]
		\item $\BPP \subseteq \class{SUBEXP}$ (i.o.), and
		\item $\BPP = \P$, unless $\NP \subseteq \class{SUBEXP}$.
	\end{enumerate}
\end{theorem}

\begin{proof} \
  For (1), combine the result of Theorem~\ref{thm:15-1} with the premise of
  Theorem~\ref{thm:bpp-in-subexp};
  for (2), combine Theorems~\ref{thm:15-2} and \ref{thm:bpp-eq-p} in the same
  way.
\end{proof}

In words, if $\mathprob{MCSP}$ is $\NP$-hard under a natural reduction from
$\mathprob{SAT}$, then every problem in $\BPP$ can be efficiently solved.
Now, we actually believe that $\P = \BPP$ as most algorithms in $\BPP$ surrender
to derandomization.
However, it is known that showing $\BPP = \P$ entails proving the existence
of certain pseudorandom generators which in turn would prove $\BPP = \P$ all
along \cite{goldreich11},
a result which seems to be challenging in its own right.
Therefore, proving the $\NP$-hardness of $\mathprob{MCSP}$ is as difficult
as finding a constructive way for derandomization.

Finally, taking everything together, we obtain a nice corollary as follows.

\begin{corollary}
	If $\mathprob{MCSP}$ is $\NP$-hard under a natural reduction from $\mathprob{SAT}$, then $\BPP \subsetneq \class{E}$
\end{corollary}

\begin{proof}
  We first show that the inclusion $\class{SUBEXP} \subseteq \class E$ is
  strict:
  By definition, $\class{SUBEXP}$ is the intersection of
  $\TIME(2^{n^\varepsilon})$ for all $\varepsilon > 0$.
  In particular, $\class{SUBEXP} \subseteq \TIME(2^{\sqrt n})$.
  Now, the deterministic time-hierarchy theorem proves that
  $\TIME(2^{\sqrt n}) \subsetneq \TIME(2^{n})$ since
  $2^{\sqrt n} \log(2^{\sqrt n}) = 2^{\sqrt n \log \sqrt n}
   \in o(2^n)$
  We conclude that
  $\class{SUBEXP} \subseteq \TIME(2^{\sqrt n}) \subsetneq \class E$
  Furthermore, from Theorem \ref{thm:BPPimplication}, we know that if
  $\mathprob{MCSP}$ is
  $\NP$-hard under a natural reduction from $\mathprob{SAT}$, then
  $\BPP \subseteq \class{SUBEXP}$.
  Combining both gives us
  $\class{BPP} \subseteq \class{SUBEXP} \subsetneq \class E$.
\end{proof}

\subsection{MCSP and P}
\label{subsect:MCSP-P}
In the previous section we have discussed the difficulties we face when proving
the $\NP$-completeness of $\mathprob{MCSP}$ under a natural reduction.
Nonetheless, in this section we consider the opposite assumption, namely that $\mathprob{MCSP}$ belongs to $\P$. As we will see, this
results in some surprising consequences which are, however, generally assumed
to be unlikely.

Let us start with providing a strong implication on the field of cryptography:
Under the premise that
$\mathprob{MCSP}$ can be efficiently solved, we are be able to factor Blum
integers\footnote{A Blum integer is a product of two distinct primes which are both congruent to $3$ mod $4$. Factoring Blum integers is believed to be as hard as factoring general integers.}
well on the average.
Specifically, let us examine the following theorem and its consequence.

\begin{theorem}
  \label{thm:nostrong}
	If $\mathprob{MCSP}$ is in $\Ppoly$, then there is no strong pseudorandom
  generator in $\Ppoly$.
\end{theorem}

This theorem is a direct consequence of the ``Natural Proofs Barrier''
conceived by Razborov and Rudich \cite{10.1006/jcss.1997.1494}.
We highly suggest this read to the interested reader.
%
We generally believe that the pseudorandom generator based on factoring (Blum)
integers is strong.
However, Theorem~\ref{thm:nostrong} rules out such a prospective, so we obtain:

\begin{corollary}
	If $\mathprob{MCSP}$ is in $\P$, then, for any $\epsilon > 0$, there is an algorithm running in time $2^{n^{\epsilon}}$ that factors Blum integers well on the average.
\end{corollary}

Thus, the corollary above suggests that if $\mathprob{MCSP}$ can be efficiently
solved, then we can break the strong pseudorandom generator of factoring Blum
integers with a good enough average-case algorithm.
%
In other words, if $\mathprob{MCSP}$ is in $\P$, then current
cryptographic schemes relying on the hardness of integer factoring
(e.g. RSA or Diffie-Hellman key exchange) are prone to efficient
attacks.
%
Even if factoring turns out to be easy, Theorem~\ref{thm:nostrong} still puts a
questionmark behind the existence of pseudorandom generators and as such
on one-way functions.
%
However,
it is mainly believed that factoring is hard
and one-way functions exist
and therefore it is very much unlikely that $\mathprob{MCSP}$ can be efficiently
solved; however, nothing has been shown to draw an ultimate conclusion about
this assumption.

% We will now explore another surprising consequence that would
% happen if such proof exists.

% In other words, if $\mathprob{MCSP}$ is in $\P$, then our current cryptography
% breaks because a fast algorithm for factoring (at least for the average-case)
% can break any type of cryptography. It is mainly believed that factoring is hard
% and therefore it is very much unlikely that $\mathprob{MCSP}$ can be efficiently
% solved; however, nothing has been shown to draw an ultimate conclusion about
% this assumption. We will now explore another surprising consequence that would
% happen if such proof exists.

% It contradicts assumptions made in cryptography:
% - One way functions exist
% - Pseudorandomnumber generators exist

\bigskip

We want to look at a second consequence of $\mathprob{MCSP} \in \P$
for randomized algorithms.
To this end, let us first examine the following theorem.

\begin{theorem}[\cite{10.1145/335305.335314}]
  \label{thm:bpp-zpp}
	$\BPP \subseteq \ZPP^{\mathprob{MCSP}}$
\end{theorem}

This is a stronger version of the previoulsy known inclusion
$\BPP \subseteq \ZPP^{\NP}$.
In fact, this can be obtained by combining the result
$\BPP \subseteq \MA$ achieved through techniques from to the Sipser-G\'acs
Theorem with $\MA \subseteq \ZPP^{\mathprob{MCSP}}$ \cite{goldreich97}.
We could obtain the Theorem~\ref{thm:bpp-zpp} easily from that if
$\mathprob{MCSP}$ were shown to be $\NP$-hard.

% However, as mentioned in section \ref{subsect:MCSP-NP}, establishing the hardness of $\mathprob{MCSP}$ is very challenging as such proof will imply a decent amount of breakthroughs in theoretical computer science. Let us now assume that it is indeed true, then if $\mathprob{MCSP}$ is in $\P$, then we have $\P = \NP$ which provides us the corollary.
Now, using the identity $\ZPP^\P = \ZPP$, we obtain the following as a corollary.

\begin{corollary}
	If $\mathprob{MCSP}$ is in $\P$, then $\BPP \subseteq \ZPP$.
\end{corollary}

We know that by definition, $\ZPP \subseteq \RP \subseteq \BPP$
(cf. \cite{arora2009}, Chapter~7).
However, it is yet unknown whether
$\BPP \subseteq \RP$ or $\BPP \subseteq \NP$.
But if $\mathprob{MCSP}$ can be
efficiently solved, then by the above corollary, we obtain $\ZPP = \RP = \BPP$
which would be a big breakthrough.
%
In particular, if $\mathprob{MCSP}$ were in $\P$, then any efficient algorithm
with two-sided error could be simulated to run efficiently in
expectation with zero-sided error.



\section{Conclusion}

% add "local reductions" (v013a004.pdf)

To summarize, the results shown in ``Circuit Minimization Problem'' by Kabanets and Cai neither give evidence against the $\NP$-hardness of $\mathprob{MCSP}$ nor refute the conjecture that $\mathprob{MCSP} \in \P$. Instead, they explain how
establishing such proofs is difficult.
%
% a daunting task since it implies some certain consequences happen for complexity classes - some seem plausible, some not, but all are beyond the scope of our current techniques.
%
First, even though we expect that $\mathprob{MCSP}$ cannot be efficiently solved,
showing its $\NP$-hardness under natural reduction entails strong statements
about circuit complexity which in turn imply the existence of certain
pseudorandom generators. Both of which are known to be difficult to obtain.
%
On the other hand, it seems likely that $\mathprob{MCSP}$ is not contained in $\P$.
This is mainly because $\mathprob{MCSP}$ being efficiently solvable contradicts
the existence of one-way functions, which is a widely held belief in cryptography.

Our research is therefore taking the direction of showing the hardness of $\mathprob{MCSP}$, which is a crucial step in obtaining the soundness of
this cryptographic assumption.
%
There has been a long sequence of work (\cite{hitchcock2015np}, \cite{allender2017minimum}, \cite{murray2017non}, \cite{allender2019new}) which tackles the results given in Section~\ref{subsect:MCSP-NP} to give further evidence of the difficulty of showing $\NP$-hardness of $\mathprob{MCSP}$. However, researchers have managed to prove that some variants of $\mathprob{MCSP}$ are $\NP$-complete. Namely, $\mathprob{DNF}$-$\mathprob{MCSP}$ \cite{masek1979some}, $\mathprob{MCSP}$ for
$\mathprob{OR-AND-MOD}$ Circuits \cite{hirahara2018np}, and $\mathprob{MCSP}$ for multi-output functions \cite{ilango2020np} are now known to be $\NP$-complete. Furthermore, some theorists have been trying to prove that $\mathprob{MCSP}$ is $\NP$-intermediate which, while still implying a separation of $\NP$ from $\P$,
avoids some of the hard ramifications we have seen for $\NP$-completeness.

We wish the reader a Merry Christmas and a Happy New Year!

% I like to use bibtex to organize reference, but you can use whatever you like. https://dblp.org/ is a good source for bibtex entries for CS papers
\bibliographystyle{alpha}
\bibliography{term_paper_bib}

\end{document}



